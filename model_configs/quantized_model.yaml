model:
  base_params:
    # Change this to your own model name on huggingface hub
    # (Optional) If you want to use a chat template, set "use_chat_template=true" after revision.
    # (Optional) However, you must ensure that the chat template is saved in the model checkpoint.
    model_args: "pretrained=unsloth/Qwen3-0.6B-Base-unsloth-bnb-4bit,revision=main"

    # If your model already has a quantization config as part of the model config, specify this as "none".
    # Otherwise. specify the model to be loaded in 4 bit. The other option is to use "8bit" quantization.
    dtype: "none"
    compile: false

  # Ignore this section, do not modify!
  merged_weights:
    delta_weights: false
    adapter_weights: false
    base_model: null
  generation:
    temperature: 0.0
